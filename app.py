import streamlit as st
import pandas as pd
import plotly.express as px
from alertes import filtrer_cve_critiques, generer_message, envoyer_email
from dotenv import load_dotenv
import os
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Configuration Streamlit
st.set_page_config(page_title="Dashboard CVE", layout="wide")

# Chargement de l'environnement
load_dotenv()
EMAIL_SENDER = os.getenv("EMAIL_SENDER")
EMAIL_PASSWORD = os.getenv("EMAIL_PASSWORD")
EMAIL_DESTINATAIRE = os.getenv("EMAIL_DESTINATAIRE")

# Chargement des donnÃ©es
@st.cache_data
def charger_donnees(path="cve_consolidated.csv"):
    df = pd.read_csv(path)
    df["Date de publication"] = pd.to_datetime(df["Date de publication"], errors="coerce")
    return df

df = charger_donnees()

st.title("ğŸ“Š Dashboard CVE â€“ Projet Mastercamp 2025")

# DÃ©claration des onglets
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ” Analyse & alertes",
    "ğŸ“Š Statistiques",
    "â„¹ï¸ Ã€ propos",
    "ğŸ““ Notebook",
    "ğŸ¤– Machine Learning"
])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 1 : Analyse & alertes
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    col1, col2, col3 = st.columns(3)
    col1.metric("ğŸ”¢ Total CVE", len(df))
    col2.metric("âš ï¸ Critiques (CVSS â‰¥ 9)", df[df["Score CVSS"] >= 9].shape[0])
    col3.metric("ğŸ“¬ Alertes envoyables", df[df["Score EPSS"] >= 0.7].shape[0])

    st.sidebar.header("ğŸ›ï¸ Filtres dynamiques")
    editeurs = st.sidebar.multiselect("Ã‰diteurs Ã  surveiller", options=sorted(df["Ã‰diteur/Vendor"].dropna().unique()), default=["Microsoft", "Cisco"])
    score_cvss_min = st.sidebar.slider("Score CVSS minimum", 0.0, 10.0, 9.0)
    score_epss_min = st.sidebar.slider("Score EPSS minimum", 0.0, 1.0, 0.7)
    options_severite = sorted(df["Base Severity"].dropna().str.lower().unique())
    severite = st.sidebar.multiselect("GravitÃ© (Base Severity)", options=options_severite, default=["critical"])

    df_filtre = df[
        (df["Score CVSS"] >= score_cvss_min) &
        (df["Score EPSS"] >= score_epss_min) &
        (df["Ã‰diteur/Vendor"].isin(editeurs)) &
        (df["Base Severity"].str.lower().isin(severite))
    ]

    st.success(f"{len(df_filtre)} CVE dÃ©tectÃ©es selon vos critÃ¨res.")
    st.subheader("ğŸ“„ DonnÃ©es filtrÃ©es")
    st.dataframe(df_filtre[["Identifiant CVE", "Ã‰diteur/Vendor", "Produit", "Score CVSS", "Score EPSS", "Base Severity"]])

    st.subheader("âœ‰ï¸ Envoi dâ€™alertes email")
    if st.button("Envoyer les alertes par mail"):
        nb_envoyes = 0
        for _, cve in df_filtre.drop_duplicates(subset="Identifiant CVE").iterrows():
            message = generer_message(cve)
            try:
                envoyer_email(
                    destinataire=EMAIL_DESTINATAIRE,
                    sujet=f"[ALERTE CVE] {cve['Identifiant CVE']}",
                    message=message,
                    sender=EMAIL_SENDER,
                    password=EMAIL_PASSWORD
                )
                nb_envoyes += 1
            except Exception as e:
                st.error(f"Erreur d'envoi pour {cve['Identifiant CVE']} : {e}")
        st.success(f"{nb_envoyes} alertes envoyÃ©es avec succÃ¨s âœ…")

    st.download_button(
        label="ğŸ“¥ TÃ©lÃ©charger les CVE filtrÃ©es",
        data=df_filtre.to_csv(index=False).encode("utf-8"),
        file_name="alertes_filtrees.csv",
        mime="text/csv"
    )

    st.subheader("ğŸ¯ Focus sur la CVE la plus critique")
    if not df_filtre.empty:
        cve_max = df_filtre.sort_values(by="Score EPSS", ascending=False).iloc[0]
        with st.expander(f"DÃ©tails de {cve_max['Identifiant CVE']}"):
            st.markdown(f"""
            - **Produit** : {cve_max['Produit']}
            - **Ã‰diteur** : {cve_max['Ã‰diteur/Vendor']}
            - **Score CVSS** : {cve_max['Score CVSS']}
            - **Score EPSS** : {cve_max['Score EPSS']}
            - **Type de vulnÃ©rabilitÃ© (CWE)** : {cve_max['Type CWE']}
            - **GravitÃ©** : {cve_max['Base Severity']}
            - **Date de publication** : {cve_max['Date de publication'].date()}
            - **Lien** : [Lien vers le bulletin]({cve_max['Lien du bulletin']})
            - **Description** : {cve_max['Description'][:400]}...
            """)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 2 : Statistiques
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    st.subheader("ğŸ“Š Statistiques globales")

    col6, col7, col8 = st.columns(3)
    col6.metric("ğŸ§© Produits impactÃ©s", df["Produit"].nunique())
    col7.metric("ğŸ¢ Ã‰diteurs diffÃ©rents", df["Ã‰diteur/Vendor"].nunique())
    col8.metric("ğŸ“… PÃ©riode couverte", f"{df['Date de publication'].min().date()} â†’ {df['Date de publication'].max().date()}")

    st.markdown("### ğŸ“Œ RÃ©partition et tendances")

    col9, col10 = st.columns(2)
    with col9:
        st.markdown("#### ğŸ” Top 10 Ã©diteurs les plus touchÃ©s")
        top_vendors = df["Ã‰diteur/Vendor"].value_counts().head(10)
        fig_vendors = px.bar(x=top_vendors.index, y=top_vendors.values, labels={"x": "Ã‰diteur", "y": "Nombre de CVE"}, title="Ã‰diteurs les plus impactÃ©s")
        st.plotly_chart(fig_vendors, use_container_width=True)

    with col10:
        st.markdown("#### ğŸš¨ RÃ©partition par gravitÃ©")
        severites = df["Base Severity"].value_counts()
        fig_sev = px.pie(names=severites.index, values=severites.values, title="RÃ©partition des niveaux de gravitÃ©", hole=0.3)
        st.plotly_chart(fig_sev, use_container_width=True)

    st.markdown("### ğŸ“ˆ CVE par mois")
    df["Mois_dt"] = df["Date de publication"].dt.to_period("M").dt.to_timestamp()
    fig_mensuel = px.line(
        df.groupby("Mois_dt").size().reset_index(name="Nombre de CVE"),
        x="Mois_dt", y="Nombre de CVE",
        title="Ã‰volution mensuelle des CVE publiÃ©es"
    )
    st.plotly_chart(fig_mensuel, use_container_width=True)

    st.markdown("### ğŸ§ª Top 10 produits les plus vulnÃ©rables")
    top_produits = df["Produit"].value_counts().head(10)
    fig_produits = px.bar(x=top_produits.index, y=top_produits.values, labels={"x": "Produit", "y": "Nombre de CVE"}, title="Produits avec le plus de CVE")
    st.plotly_chart(fig_produits, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 3 : Ã€ propos
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab3:
    st.markdown("""
    ## ğŸ” Contexte

    Ce projet vise Ã  automatiser la **surveillance des vulnÃ©rabilitÃ©s de cybersÃ©curitÃ©** Ã  partir des publications officielles de l'ANSSI.

    Les donnÃ©es sont enrichies via :
    - L'API **MITRE** pour les dÃ©tails techniques (CWE, CVSS)
    - L'API **EPSS** pour la probabilitÃ© d'exploitation
    - Les bulletins **avis** et **alertes** du [CERT-FR](https://www.cert.ssi.gouv.fr/)

    ## ğŸ¯ Objectifs
    - Identifier rapidement les menaces critiques
    - Permettre une rÃ©action proactive (envoi dâ€™alertes)
    - Visualiser lâ€™Ã©volution des risques dans le temps

    ## ğŸ“‚ FonctionnalitÃ©s
    - Filtres dynamiques (Ã©diteur, gravitÃ©, score, dateâ€¦)
    - Envoi automatisÃ© dâ€™email dâ€™alerte
    - Export CSV des vulnÃ©rabilitÃ©s critiques
    - Graphiques de suivi

    ---
    âœ… **Projet Mastercamp 2025** â€“ RÃ©alisÃ© par : Sidy Doucoure, Ilyesse Essalihi, Samy Boudiba, Diaby Diakite 
    ğŸ”— [ANSSI - CERT-FR](https://www.cert.ssi.gouv.fr/) | ğŸ› ï¸ Python â€¢ Pandas â€¢ Streamlit â€¢ Plotly  
    
    """)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 4 : Notebook HTML (analyse_cve.html)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab4:
    st.subheader("ğŸ““ Analyse exploratoire â€“ Notebook Jupyter")
    try:
        with open("analyse_cve.html", "r", encoding="utf-8") as f:
            notebook_html = f.read()
        st.components.v1.html(notebook_html, height=1000, scrolling=True)
    except FileNotFoundError:
        st.error("âŒ Le fichier `analyse_cve.html` est introuvable. Assurez-vous qu'il est bien dans le mÃªme dossier que `app.py`.")
 
with tab5:
    st.header("Machine Learning : Clustering & Classification")

    # PrÃ©paration des donnÃ©es
    df_ml = df[['Score CVSS', 'Score EPSS', 'Type CWE', 'Ã‰diteur/Vendor', 'Base Severity']].copy()
    df_ml.dropna(inplace=True)

    # Encodage des colonnes catÃ©gorielles avec mise en cache
    @st.cache_data
    def encode_data(df_in):
        le_cwe = LabelEncoder()
        le_vendor = LabelEncoder()
        le_severity = LabelEncoder()

        df_in['Type CWE Encoded'] = le_cwe.fit_transform(df_in['Type CWE'].astype(str))
        df_in['Ã‰diteur/Vendor Encoded'] = le_vendor.fit_transform(df_in['Ã‰diteur/Vendor'].astype(str))
        df_in['Base Severity Encoded'] = le_severity.fit_transform(df_in['Base Severity'].astype(str))
        return df_in, le_cwe, le_vendor, le_severity

    df_ml, le_cwe, le_vendor, le_severity = encode_data(df_ml)

    # Features et target
    X = df_ml[['Score CVSS', 'Score EPSS', 'Type CWE Encoded']]
    y = df_ml['Base Severity Encoded']

    # Normalisation
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Choix interactif du nombre de clusters
    n_clusters = st.slider("Nombre de clusters KMeans", min_value=2, max_value=10, value=3, step=1)

    # Clustering KMeans
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    clusters = kmeans.fit_predict(X_scaled)
    df_ml['Cluster'] = clusters

    st.subheader("Clustering KMeans")
    st.write(f"Nombre de clusters : {n_clusters}")
    st.dataframe(df_ml[['Score CVSS', 'Score EPSS', 'Type CWE', 'Cluster']].head(10))

    # Visualisation clustering CVSS vs EPSS (figsize rÃ©duit)
    fig, ax = plt.subplots(figsize=(5, 4))
    sns.scatterplot(
        data=df_ml,
        x="Score CVSS",
        y="Score EPSS",
        hue="Cluster",
        palette="Set2",
        ax=ax
    )
    ax.set_title("Clustering des vulnÃ©rabilitÃ©s (CVSS vs EPSS)")
    st.pyplot(fig)

    # Classification Random Forest
    st.subheader("Classification Random Forest sur la sÃ©vÃ©ritÃ©")
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.5, random_state=42)
    clf = RandomForestClassifier(random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    st.text("Rapport de classification :")
    labels_presentes = sorted(list(set(y_test)))
    report = classification_report(
        y_test,
        y_pred,
        labels=labels_presentes,
        target_names=le_severity.inverse_transform(labels_presentes)
    )
    st.text(report)

    # Matrice de confusion (figsize rÃ©duit)
    conf_mat = confusion_matrix(y_test, y_pred)
    fig2, ax2 = plt.subplots(figsize=(5, 4))
    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',
                xticklabels=le_severity.classes_, yticklabels=le_severity.classes_, ax=ax2)
    ax2.set_xlabel("Valeurs prÃ©dites")
    ax2.set_ylabel("Valeurs rÃ©elles")
    ax2.set_title("Matrice de confusion")
    st.pyplot(fig2)

    # Importance des variables (figsize rÃ©duit)
    importances = clf.feature_importances_
    features = ['Score CVSS', 'Score EPSS', 'Type CWE']
    fig3, ax3 = plt.subplots(figsize=(5, 3))
    sns.barplot(x=importances, y=features, ax=ax3)
    ax3.set_title("Importance des variables (Random Forest)")
    st.pyplot(fig3)

    # PrÃ©diction interactive
    st.subheader("PrÃ©diction interactive de la sÃ©vÃ©ritÃ©")

    # Construire une liste avec index et Identifiant CVE
    options = [f"{idx} - {cve}" for idx, cve in zip(df_ml.index, df.loc[df_ml.index, 'Identifiant CVE'])]

    choix = st.selectbox("Choisir un CVE par index", options)

    if choix:
        idx_selectionne = int(choix.split(" - ")[0])
        sample = X_scaled[idx_selectionne].reshape(1, -1)
        pred_code = clf.predict(sample)[0]
        pred_severity = le_severity.inverse_transform([pred_code])[0]
        st.write(f"PrÃ©diction de la sÃ©vÃ©ritÃ© : **{pred_severity}**")